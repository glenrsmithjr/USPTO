Elastipy is a template package that allows a user to interface with the elasticsearch cluster on the ISAD servers.

Browse the cluster by going here: http://192.168.10.105:7021.

- [Using the Code](#using-the-code)
- [Package Functions](#index-functions)
- [Search Functions](#search-functions)

# Using the Code

Before you can use these functions to interface with elasticsearch, you need to have a few modules installed: [json, pandas, requests, sys]

Some of these come packaged with python, the others will need to be installed via whatever method you use to install modules in your environment. Usually, this is through pip. Ex: `pip install pandas`

To use the elastipy module:

1. Copy the "elastipy" directory (containing the elastipy.py file and requirements folder) into the same directory as your script or shell.
2. If using a shell, run the command `from elastipy.elastipy import *`. If using a script, place the command at the top of your file.

This will import all of the functions from the elastipy module and all necessary requirements.

Note: If using this package on the ISAD servers in a container, use it on servers 2-6. You will not be able to use it on ISAD 1 (192.168.10.105) since that IP is used to access elasticsearch, and containers on ISAD 1 can't access ISAD 1 via its IP address.

# Index Functions

This package contains various functions to interface with an elasticsearch instance. The following table lists the functions.

|Function|Details|Parameters|Examples|Return|
|--------|-------|----------|--------|-------|
|create_index	| Creates an index in the elasticsearch instance | **es** (es object): The elasticsearch client obtained from the function _es_connect_ <br> **index** (string): The name of the index you would like to create <br> **fields** (list of strings): If you are not providing your own field mappings, this field must be present to create default field mappings, which will all be of type "text". Default: None <br> **field\_mappings** (list of two-tuples): If you are providing your own field mappings, they must be in a list of two-tuples, where each tuple contains first the name of the field as a string, and then a mapping dictionary. Default: None | **es**: es_client <br> **index**: 'myIndex' <br> **field\_mappings**: [('field1', {'type': 'text'}), ('field2', {'type': 'geo_point'})] <br> **fields**: None | N/A |
|delete_index	| Deletes an index from the elasticsearch instance | **es** (es object): The elasticsearch client obtained from the function _es_connect_ <br> **index** (string): The name of the index you would like to create | **es**: es_client <br> **index**: 'myIndex' | N/A |
|es_connect	| Connects to an elasticsearch instance. You do not need to pass in parameters, although you have the option to do so | **host** (string): The IP address of the elasticsearch instance host. The default will automatically connect you. You only need to provide a value if the default value is no longer accurate. Default: '192.168.10.105' <br> **port** (integer): The port of the elasticsearch instance. The default will automatically connect you. You only need to provide a value if the default value is no longer accurate. Default: 7020 | **host**: '192.168.10.105' <br> **port**: 7020| Elasticsearch Client Object |
|index_data	| Indexes data into an index in bulk | **es** (es object): The elasticsearch client obtained from the function _es_connect_ **index** (string): The name of the index you would like to create <br> **data** (DataFrame): The data as a dataframe <br> **id\_counter** (integer): This param is used to assign unique ID values to each document indexed into elasticsearch. It is very important that these are unique, or else elasticsearch will delete older documents when new documents are indexed with the same IDs. If you pass your entire dataset into this function, this is taken care of for you. However, if you need to index your data in chunks, be sure to keep a counter in your script that increments by the chunk size and pass that value into this function. <br> **use\_column\_ids** (boolean): Whether to use a column in the dataframe as the unique IDs when indexing. If this value is set to True, you must provide the name of the column in _id_column_. Default: False <br> **id\_column** (string): The column to use to create unique IDs. Default: None | **es**: es_client <br> **index**: 'myIndex' <br> **data**: (DataFrame) <br> **id\_counter**: 0 <br> **use\_column\_ids**: True <br> **id\_column**: 'uuid' | N/A |
| index_exists	| Checks whether an index exists or not  | **es** (es object): The elasticsearch client obtained from the function _es_connect_ <br> **index** (string): The name of the index you would like to check | **es**: es_client <br> **index**: 'myIndex' | True if index exists, False otherwise. |

# Search Functions

|Function|Details|Parameters|Examples|Return|
|--------|-------|----------|--------|-------|
| boolean_search | Allows user to search elasticsearch with a boolean query |**index** (string): The name of the index you would like to create <br> **fields\_to\_search** (list): A list of fields to search in a dataset. These column names must match the true column names exactly. <br> **query** (string): The boolean query to use in the search <br> **fields\_to\_return** (list): A list of fields to return in the resulting dataframe, or 'all' to return all fields. Default: 'all' <br> **es** (es object): The elasticsearch client obtained from the function _es_connect_. If no value is provided, the client will be connect to the es-cluster at 192.168.10.105:7020 <br> **result\_window**: The number of results to return. This value can not exceed 10,000. If you would like more than 10,000 results, set _scroll_ to True. See _scroll_ for details.  Default: 10000 <br> **verbose** (boolean): If True, the result returned is the full json response. If False, only the data is returned in the form of a pandas dataframe. <br> **scroll** (boolean): Whether to paginate through the results. If scroll is set to True, Verbose is not used and only the data is returned. Default: False <br> **max\_results** (integer): The maximum number of documents to collect. This can be set to any number, or -1 to collect all hits. Default: 100000 <br> **stream\_to\_file** (boolean) Whether to save the results of the search to a file. If True, _filename_ must be set. See _filename_ for details. Default: False <br> **filename** (string) The full or relative path of where to save data pulled from elasticsearch if _stream\_to\_file_ is True. Default: None|**index**: 'myIndex' <br> **fields\_to\_search**: ['title', 'abstract'] <br> **query**: (machine AND learning) <br> **fields\_to\_return**: ['title', 'abstract', 'date'] <br> **es**: es_client <br> **result\_window**: 5000 <br> **verbose**: False <br> **scroll**: True <br> **max\_results**: 50000 <br> **stream\_to\_file**: True <br> **filename**: 'myData.tsv'| Pandas Dataframe or None if _stream_to_file_ is True|
| custom_search | Allows user to search elasticsearch with a custom query |**index** (string): The name of the index you would like to create <br> **query** (dictonary): A custom query to pass into elasticsearch <br> **es** (es object): The elasticsearch client obtained from the function _es_connect_. If no value is provided, the client will be connect to the es-cluster at 192.168.10.105:7020 <br> **fields\_to\_return** (list): A list of fields to return in the resulting dataframe, or 'all' to return all fields. Default: 'all' <br> **query** (dictonary): The custom query to use. This will be formatted as a dictionary <br> **result\_window**: The number of results to return. This value can not exceed 10,000. If you would like more than 10,000 results, set _scroll_ to True. See _scroll_ for details.  Default: 10000 <br> **verbose** (boolean): If True, the result returned is the full json response. If False, only the data is returned in the form of a pandas dataframe. <br> **scroll** (boolean): Whether to paginate through the results. If scroll is set to True, Verbose is not used and only the data is returned. Default: False <br> **max\_results** (integer): The maximum number of documents to collect. This can be set to any number, or -1 to collect all hits. Default: 100000 <br> **stream\_to\_file** (boolean) Whether to save the results of the search to a file. If True, _filename_ must be set. See _filename_ for details. Default: False <br> **filename** (string) The full or relative path of where to save data pulled from elasticsearch if _stream\_to\_file_ is True. Default: None|**index**: 'myIndex' <br> **fields\_to\_search**: ['title', 'abstract'] <br> **query**: { "query": "match_all": {} } <br> **fields\_to\_return**: ['title', 'abstract', 'date'] <br> **es**: es_client <br> **result\_window**: 5000 <br> **verbose**: False <br> **scroll**: True <br> **max\_results**: 50000 <br> **stream\_to\_file**: True <br> **filename**: 'myData.tsv'| Pandas Dataframe or None if _stream_to_file_ is True|
| get_count | Allows user to get count of documents returned from user-provided query. You can build your own query or use the _get_query_by_type_ utility function to build one before passing it into this function. |<br> **index** (string): The name of the index you would like to create <br> **query** (dictonary): A custom query to pass into elasticsearch <br> **es** (es object): The elasticsearch client obtained from the function _es_connect_. If no value is provided, the client will be connect to the es-cluster at 192.168.10.105:7020|**index**: 'myIndex' <br> **query**: { "query": "match_all": {} } <br> **es**: es_client | Count of documents|
| get_total_count | Utility function to quickly get a count of all documents in an index. |<br> **index** (string): The name of the index you would like to create <br> **es** (es object): The elasticsearch client obtained from the function _es_connect_. If no value is provided, the client will be connect to the es-cluster at 192.168.10.105:7020|**index**: 'myIndex' <br> **es**: es_client | Count of documents|
| get_query_by_type | Builds a query from provided fields and provided query type. Supports building a boolean, vector, or search all (match all) query. If you want to search all documents, or get the count of all documents in an index, you can use the special functions: _search_all()_ and _get_total_count()_. **Note: This function does not search an index. It only provides the query structure that can be used to search any index.** |**query\_type** (string): One of {'boolean', 'vector', 'search_all'}. The appropriate fields must be present depending on the query_type. For a boolean query, you must provide a value for _query_, _fields_to_search_, and (optionally )_fields_to_return_. For a vector query, you must provide a value for _query_vector_, _vector_field_name_, and (optionally) _fields_to_return_. For a search all query, you only need to optionally provide a value for _fields_to_return_. <br> **query** (string): A boolean query if _query_type_ is 'boolean', otherwise not required <br> **fields\_to\_search** (list): A list of fields to search in a dataset. These column names must match the true column names exactly. Only required if query_type is 'boolean' <br> **fields\_to\_return** (list): A list of fields to return in the resulting dataframe, or 'all' to return all fields. Default: 'all' <br> **query\_vector** (list): A list of float values that represent a vector in the document vector space. The length of the list must be the same as the length of the document vectors in the dataset. Only required if _query_type_ is 'vector'| | A dictionary containing the query|
| search_all | Returns all documents from an index |<br> **index** (string): The name of the index you would like to create <br> **es** (es object): The elasticsearch client obtained from the function _es_connect_. If no value is provided, the client will be connect to the es-cluster at 192.168.10.105:7020 <br> **fields\_to\_return** (list): A list of fields to return in the resulting dataframe, or 'all' to return all fields. Default: 'all' <br> **query** (dictonary): The custom query to use. This will be formatted as a dictionary <br>**stream\_to\_file** (boolean) Whether to save the results of the search to a file. If True, _filename_ must be set. See _filename_ for details. Default: False <br> **filename** (string) The full or relative path of where to save data pulled from elasticsearch if _stream\_to\_file_ is True. Default: None|**index**: 'myIndex' <br> **fields\_to\_return**: ['title', 'abstract', 'date'] <br> **es**: es_client <br> **stream\_to\_file**: True <br> **filename**: 'myData.tsv'| Pandas Dataframe or None if _stream_to_file_ is True|
| vector_search | Allows user to search elasticsearch with a vector query | **index** (string): The name of the index you would like to create <br> **query\_vector** (list): A list of float values that represent a vector in the document vector space. The length of the list must be the same as the length of the document vectors in the dataset. <br> **vector\_field\_name** (string): The name of the field where vectors are stored in the elasticsearch dataset. <br> **fields\_to\_return** (list): A list of fields to return in the resulting dataframe, or 'all' to return all fields. Default: 'all' <br> **es** (es object): The elasticsearch client obtained from the function _es_connect_. If no value is provided, the client will be connect to the es-cluster at 192.168.10.105:7020 <br> **result\_window**: The number of results to return. This value can not exceed 10000. Default: 10000 <br> **verbose** (boolean): If True, the result returned is the full json response. If False, only the data is returned in the form of a pandas dataframe. <br> **scroll** (boolean): Whether to paginate through the results. If scroll is set to True, Verbose is not used and only the data is returned. Default: False <br> **max\_results** (integer): The maximum number of documents to collect. This can be set to any number, or -1 to collect all hits. Default: 100000 <br> **stream\_to\_file** (boolean) Whether to save the results of the search to a file. If True, _filename_ must be set. See _filename_ for details. Default: False <br> **filename** (string) The full or relative path of where to save data pulled from elasticsearch if _stream\_to\_file_ is True. Default: None| **es**: es_client <br> **index**: 'myIndex' <br> **query\_vector**: [0.43, -0.012, -0.22, ...] <br> **vector\_field\_name**: 'docvecs' <br> **fields\_to\_return**: ['title', 'abstract', 'date'] <br> **result\_window**: 5000 <br> **verbose**: False <br> **scroll**: True <br> **max\_results**: 50000 <br> **stream\_to\_file**: True <br> **filename**: 'myData.tsv'| Pandas Dataframe or None if _stream_to_file_ is True|


Notes:
 * The `chunk_size` parameter in the line `helpers.bulk(es, json_parsed, chunk_size=1000, request_timeout=100)` in the function index_data() is not arbitrary and was chosen to avoid memory or timeout errors. If your data has a larger than normal size per 1000 rows, you may need to adjust this down. 


